syntax = "proto2";

import "protos/hyperparams.proto";

message ProjectionLayer {
  optional Hyperparams fc_hyperparams = 1;

  optional int32 output_dims = 2;

  optional string scope = 3 [ default = 'detection/project'];
}

// FRCNN configs.
message FRCNN {
  // Feature extractor config.
  optional FasterRcnnFeatureExtractor feature_extractor = 1;

  // Whether to update batch_norm inplace during training. This is required
  // for batch norm to work correctly on TPUs. When this is false, user must add
  // a control dependency on tf.GraphKeys.UPDATE_OPS for train/loss op in order
  // to update the batch norm moving average parameters.
  optional bool inplace_batchnorm_update = 2 [default = false];

  // Output size (width and height are set to be the same) of the initial
  // bilinear interpolation based cropping during ROI pooling.
  optional int32 initial_crop_size = 3;

  // Kernel size of the max pool op on the cropped feature map during
  // ROI pooling.
  optional int32 maxpool_kernel_size = 4;

  // Stride of the max pool op on the cropped feature map during ROI pooling.
  optional int32 maxpool_stride = 5;

  // Keep probability of the dropout layer.
  optional float dropout_keep_prob = 6 [default = 1.0];

  // If true, add a dropout layer after extracting feature map.
  optional bool dropout_on_feature_map = 7 [default = true];

  // Path to the pre-trained checkpoint.
  optional string checkpoint_path = 8;

  // If true, the pretrained model involves scopes such as:
  //   first_stage_feature_extraction and second_stage_feature_extraction
  optional bool from_detection_checkpoint = 9;

  // If true, also load the pretrained layer of 'detection/project'.
  optional ProjectionLayer projection_layer = 10;
}

message FasterRcnnFeatureExtractor {
  // Type of Faster R-CNN model (e.g., 'faster_rcnn_resnet101';
  // See builders/model_builder.py for expected types).
  optional string type = 1;

  // Output stride of extracted RPN feature map.
  optional int32 first_stage_features_stride = 2 [default=16];

  // Whether to update batch norm parameters during training or not.
  // When training with a relative large batch size (e.g. 8), it could be
  // desirable to enable batch norm update.
  optional bool batch_norm_trainable = 3 [default=false];
}
